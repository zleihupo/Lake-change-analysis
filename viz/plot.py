# -*- coding: utf-8 -*-
"""plot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kYVE6RijS_qQJRaco_o-5M7tFvEqldRK
"""

from google.colab import drive
drive.mount('/content/drive')

# 选 "drive" 或 "upload"
MODE = "drive"  # "drive" 或 "upload"

# 当 MODE="drive" 时，设置你的 Drive 根目录（改成你的路径）
DRIVE_ROOT = "/content/drive/MyDrive"  # ←改成你的

# 是否把生成的图也拷回 Drive_ROOT
SAVE_TO_DRIVE = True

!sudo apt-get update -y
!sudo apt-get install -y chromium-chromedriver
!pip install -q selenium pandas matplotlib opencv-python

import os, glob, zipfile, time, json, random
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt

if MODE == "drive":
    from google.colab import drive
    drive.mount('/content/drive')
    # 约定文件路径（按你的目录结构调整）
    TEST_IMG_DIR  = f"{DRIVE_ROOT}/dataset/test/images/"        # 或 images/
    TEST_MASK_DIR = f"{DRIVE_ROOT}/dataset/test/masks/"         # 或 masks/
    UNET_NPY      = f"{DRIVE_ROOT}/evaluation_results/pred_unet_test.npy"
    SEGNET_NPY    = f"{DRIVE_ROOT}/evaluation_results/pred_segnet_test.npy"
    FCN_NPY       = f"{DRIVE_ROOT}/evaluation_results/pred_fcn_test.npy"
    # 地图 HTML（模糊匹配, 可不用改）
    GLOBAL_HTML = next((f for f in glob.glob(f"{DRIVE_ROOT}/lake_analysis_outputs/global_heatmap_lakes_trends (1).html") if "global" in f.lower() or "heatmap" in f.lower()), None)
    REGION_HTML = next((f for f in glob.glob(f"{DRIVE_ROOT}/lake_analysis_outputs/region_trends_map (1).html") if "region" in f.lower()), None)
    # 时间序列与重要度 CSV（可按需调整）
    TS_CSV = next((f for f in glob.glob(f"{DRIVE_ROOT}/lake_analysis_outputs/100Lake_area_Temperature_2000-2025.csv") if "Lake" in f or "Temperature" in f or "2000" in f), None)
    PERM_CSV = next((f for f in glob.glob(f"{DRIVE_ROOT}/lake_analysis_outputs/Permutation_importance（按区域，夏季）.csv") if "Permutation" in f), None)
    TOP3_CSV = next((f for f in glob.glob(f"{DRIVE_ROOT}/lake_analysis_outputs/各区域_Top-3_重要特征（夏季）.csv") if "Top-3" in f or "Top3" in f), None)

else:
    from google.colab import files
    print("👉 请选择需要的文件（可多选）：测试影像/掩膜 ZIP、NPY、HTML、CSV 等")
    uploaded = files.upload()
    # 若上传了zip，解压
    def unzip_if_exists(zipname, outdir):
        if os.path.exists(zipname):
            os.makedirs(outdir, exist_ok=True)
            with zipfile.ZipFile(zipname, 'r') as zf:
                zf.extractall(outdir)
            print(f"Unzipped: {zipname} -> {outdir}")
    unzip_if_exists("test_images.zip", "test_images")
    unzip_if_exists("test_masks.zip", "test_masks")

    # 猜目录
    def guess_dir(root):
        if os.path.isdir(root): return root
        for d in glob.glob("*"):
            if os.path.isdir(d) and ("image" in d.lower() or "mask" in d.lower()):
                return d
        return root
    TEST_IMG_DIR  = guess_dir("test_images")
    TEST_MASK_DIR = guess_dir("test_masks")

    # 猜测 NPY/HTML/CSV 文件
    UNET_NPY   = next((k for k in uploaded if "unet"   in k and k.endswith(".npy")), None)
    SEGNET_NPY = next((k for k in uploaded if "segnet" in k and k.endswith(".npy")), None)
    FCN_NPY    = next((k for k in uploaded if "fcn"    in k and k.endswith(".npy")), None)
    BEST_JSON  = "best_ensemble.json" if "best_ensemble.json" in uploaded else None
    GRID_CSV   = next((k for k in uploaded if k.endswith(".csv") and "grid" in k.lower()), None)

    GLOBAL_HTML = next((k for k in uploaded if k.endswith(".html") and ("global" in k.lower() or "heatmap" in k.lower())), None)
    REGION_HTML = next((k for k in uploaded if k.endswith(".html") and "region" in k.lower()), None)
    TS_CSV  = next((k for k in uploaded if k.endswith(".csv") and ("Lake" in k or "Temperature" in k or "2000" in k)), None)
    PERM_CSV = next((k for k in uploaded if k.endswith(".csv") and "Permutation" in k), None)
    TOP3_CSV = next((k for k in uploaded if k.endswith(".csv") and ("Top-3" in k or "Top3" in k)), None)

print("IMG_DIR:", TEST_IMG_DIR)
print("MSK_DIR:", TEST_MASK_DIR)
print("NPY:", UNET_NPY, SEGNET_NPY, FCN_NPY)
print("HTML:", GLOBAL_HTML, REGION_HTML)
print("TS_CSV:", TS_CSV, "PERM_CSV:", PERM_CSV, "TOP3_CSV:", TOP3_CSV)

def read_img_rgb(path, size=None):
    img = cv2.imread(path);
    if img is None: raise FileNotFoundError(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    if size and img.shape[:2] != size:
        img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)
    return (img.astype(np.float32)/255.)

def read_mask_bin(path, size=None):
    m = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if m is None: raise FileNotFoundError(path)
    if size and m.shape[:2] != size:
        m = cv2.resize(m, size, interpolation=cv2.INTER_NEAREST)
    return (m>127).astype(np.uint8)

def load_pairs(img_dir, msk_dir):
    img_paths = sorted(glob.glob(os.path.join(img_dir, "*")))
    pairs = []
    for ip in img_paths:
        stem = os.path.splitext(os.path.basename(ip))[0]
        mp = None
        for ext in (".png",".jpg",".jpeg",".tif",".tiff",".bmp"):
            p = os.path.join(msk_dir, stem+ext)
            if os.path.exists(p): mp = p; break
        if mp: pairs.append((ip, mp))
    if not pairs: raise RuntimeError("未找到 (image, mask) 配对，请检查影像与掩膜目录")
    return pairs

# HTML→PNG 截图
def html_to_png(html_path, out_png="map.png", width=1600, height=1000, wait_sec=3):
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument(f"--window-size={width},{height}")
    driver = webdriver.Chrome(options=chrome_options)
    driver.get("file://" + os.path.abspath(html_path))
    time.sleep(wait_sec)
    driver.save_screenshot(out_png)
    driver.quit()
    print("Saved:", out_png)

pairs = load_pairs(TEST_IMG_DIR, TEST_MASK_DIR)

def save_triptych(img_path, msk_path, out_path, size=(256, 256), show=True):
    # 读图并可选缩放；RGB 归一化到 [0,1]
    img = read_img_rgb(img_path, size=size)
    # 读掩膜并可选缩放；转二值(0/1)，用最近邻保证边界不糊
    msk = read_mask_bin(msk_path, size=size)

    # 一行三列：Image / GSW mask / overlay
    fig, ax = plt.subplots(1, 3, figsize=(9, 3))
    ax[0].imshow(img);                 ax[0].set_title("Image");     ax[0].axis("off")
    ax[1].imshow(msk, cmap="gray");    ax[1].set_title("GSW mask");  ax[1].axis("off")
    ax[2].imshow(img);
    ax[2].imshow(msk, cmap="gray", alpha=0.35)  # 半透明叠加便于对齐检查
    ax[2].set_title("Aligned pair");   ax[2].axis("off")

    plt.tight_layout()
    plt.savefig(out_path, dpi=300)     # 先保存，避免 show 后交互式渲染影响边距
    if show:
        plt.show()                     # 显示要在 close 之前
    plt.close(fig)                     # 释放内存（批量生成图时很重要）
    print("Saved:", out_path)

# 示例：用第一个样本生成 Fig.2
save_triptych(pairs[968][0], pairs[968][1], "Fig2_sample_triptych.png", size=(256, 256), show=True)

# 读取概率缓存
pred_unet   = np.load(UNET_NPY).squeeze()
pred_segnet = np.load(SEGNET_NPY).squeeze()
pred_fcn    = np.load(FCN_NPY).squeeze()
N = len(pairs)
assert pred_unet.shape[0]==pred_segnet.shape[0]==pred_fcn.shape[0]==N, "NPY 数量与样本不一致"

# 最优 (w, τ)
best = {"w":[0.3,0.3,0.4], "tau_ens":0.39, "tau_unet":0.5, "tau_segnet":0.5, "tau_fcn":0.5}

wU, wS, wF = best["w"]
tauU = best.get("tau_unet",0.5); tauS = best.get("tau_segnet",0.5); tauF = best.get("tau_fcn",0.5); tauE = best.get("tau_ens",0.5)

# 选首/中/尾三个样本
idxs = [4, 298, 1135] if N>=3 else [0]
H,W = pred_unet.shape[1], pred_unet.shape[2]

fig, axes = plt.subplots(len(idxs), 6, figsize=(24, 3*len(idxs)))
if len(idxs)==1: axes = np.array([axes])

for r, idx in enumerate(idxs):
    ip, mp = pairs[idx]
    img = read_img_rgb(ip, (H,W))
    gt  = read_mask_bin(mp, (H,W))
    pU, pS, pF = pred_unet[idx], pred_segnet[idx], pred_fcn[idx]
    pE = wU*pU + wS*pS + wF*pF
    mU = (pU>=tauU).astype(np.uint8)
    mS = (pS>=tauS).astype(np.uint8)
    mF = (pF>=tauF).astype(np.uint8)
    mE = (pE>=tauE).astype(np.uint8)

    axes[r,0].imshow(img);            axes[r,0].set_title("Image");    axes[r,0].axis("off")
    axes[r,1].imshow(gt, cmap="gray");axes[r,1].set_title("GSW mask"); axes[r,1].axis("off")
    axes[r,2].imshow(mU, cmap="gray");axes[r,2].set_title("U-Net");    axes[r,2].axis("off")
    axes[r,3].imshow(mS, cmap="gray");axes[r,3].set_title("SegNet");   axes[r,3].axis("off")
    axes[r,4].imshow(mF, cmap="gray");axes[r,4].set_title("FCN");      axes[r,4].axis("off")
    axes[r,5].imshow(mE, cmap="gray");axes[r,5].set_title(f"Ensemble\nw=({wU},{wS},{wF}), τ={tauE}"); axes[r,5].axis("off")

plt.tight_layout()
plt.savefig("Fig3_qualitative_comparison.png", dpi=300)
plt.show()
plt.close(fig)
print("Saved: Fig3_qualitative_comparison.png")

if GLOBAL_HTML and os.path.exists(GLOBAL_HTML):
    html_to_png(GLOBAL_HTML, "Fig6_global_trends.png", width=1600, height=1000, wait_sec=3)
    img = cv2.cvtColor(cv2.imread("Fig6_global_trends.png"), cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(12,7)); plt.imshow(img); plt.axis('off')
    plt.title("Fig.6 Global trends (screenshot)");
    plt.show()  # <—— 显示

if REGION_HTML and os.path.exists(REGION_HTML):
    html_to_png(REGION_HTML, "Fig7_region_trends.png", width=1600, height=1000, wait_sec=3)
    img = cv2.cvtColor(cv2.imread("Fig7_region_trends.png"), cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(12,7)); plt.imshow(img); plt.axis('off')
    plt.title("Fig.7 Regional trends (screenshot)")
    plt.show()  # <—— 显示

# ===== Fig.8（鲁棒版）：自动计算 area_index 并绘制区域小倍图 =====
import os, numpy as np, pandas as pd, matplotlib.pyplot as plt, math

# 若前面自动搜索不到，就手动指定 CSV 路径：
# TS_CSV = "/content/drive/MyDrive/your_project_folder/100Lake_area_Temperature_2000-2025.csv"

assert TS_CSV is not None and os.path.exists(TS_CSV), f"未找到时间序列CSV：{TS_CSV}"
df = pd.read_csv(TS_CSV)

# 1) year 列推断
if "year" not in df.columns:
    if "date" in df.columns:
        df["year"] = pd.to_datetime(df["date"]).dt.year
    elif "Year" in df.columns:
        df["year"] = df["Year"]
    else:
        raise ValueError("CSV 需包含 year 或 date 列（无法推断年份）。")

# 2) lake / region 列名推断
def find_col(cands):
    for c in cands:
        if c in df.columns: return c
    for col in df.columns:
        l = col.lower()
        if any(k in l for k in cands): return col
    return None

lake_col   = find_col(["lake","lakename","name","湖","地点"])
region_col = find_col(["region","zone","area","区域","地区"])
if lake_col is None:
    # 没有 lake 列也可以，只是无法做“按湖泊基线”，退化为整体基线
    print("⚠️ 未检测到 lake 列，将使用全体样本的全局基线。")
if region_col is None:
    print("⚠️ 未检测到 region 列，全部归为 'All'。")
    region_col = "region"
    df[region_col] = "All"

# 3) 面积列推断（任选其一）
area_candidates = ["area_index","area_m2","area_km2","area","面积","Area","AREA"]
area_col = None
for c in area_candidates:
    if c in df.columns:
        area_col = c
        break
if area_col is None:
    # 宽松匹配
    for col in df.columns:
        l = col.lower()
        if "area" in l:
            area_col = col; break
if area_col is None:
    raise ValueError("CSV 中未找到面积列（例如 area_m2/area_km2/area）。")

print(f"检测到列：year={ 'year' }, region={region_col}, lake={lake_col}, area={area_col}")

# 4) 若已自带 area_index 就直接用；否则计算 area_index
if "area_index" not in df.columns:
    # 面积转为数值
    df[area_col] = pd.to_numeric(df[area_col], errors="coerce")
    df = df.dropna(subset=[area_col, "year"])

    BASELINE_YEARS = {2000,2001,2002}

    def compute_baseline(g):
        # 优先用 2000–2002 的均值；若缺失则用该湖最早的 3 条记录均值
        cand = g[g["year"].isin(BASELINE_YEARS)][area_col]
        if cand.dropna().shape[0] >= 1:
            return float(cand.mean())
        return float(g.sort_values("year")[area_col].head(3).mean())

    if lake_col is not None:
        base_map = df.groupby(lake_col).apply(compute_baseline).to_dict()
        df["__baseline__"] = df[lake_col].map(base_map)
    else:
        # 无 lake 列：用全体的基线（2000–2002 或最早3条）
        all_base = compute_baseline(df.copy())
        df["__baseline__"] = all_base

    df = df[df["__baseline__"] > 0]
    df["area_index"] = df[area_col] / df["__baseline__"]
else:
    # 若已有 area_index，确保是数值
    df["area_index"] = pd.to_numeric(df["area_index"], errors="coerce")
    df = df.dropna(subset=["area_index"])

# 5) 按 region-year 聚合并绘图
g = df.groupby([region_col,"year"], as_index=False)["area_index"].mean()

regions = sorted(g[region_col].unique().tolist())
ncol = min(3, len(regions)) if len(regions)>0 else 1
nrow = math.ceil(len(regions)/ncol) if len(regions)>0 else 1

fig, axes = plt.subplots(nrow, ncol, figsize=(5*ncol, 3.2*nrow), squeeze=False)

for i, reg in enumerate(regions):
    r, c = divmod(i, ncol)
    gi = g[g[region_col]==reg].sort_values("year")
    axes[r,c].plot(gi["year"], gi["area_index"], marker='o')
    if gi.shape[0] >= 2:
        x = gi["year"].values.astype(float); y = gi["area_index"].values.astype(float)
        k = np.polyfit(x, y, 1)
        axes[r,c].plot(x, k[0]*x + k[1], linestyle="--")
    axes[r,c].set_title(reg)
    axes[r,c].set_xlabel("Year"); axes[r,c].set_ylabel("Summer area index")
    axes[r,c].grid(True, linestyle="--", alpha=0.3)

# 关多余子图
for j in range(len(regions), nrow*ncol):
    r, c = divmod(j, ncol); axes[r,c].axis("off")

plt.tight_layout()
plt.savefig("Fig8_region_small_multiples.png", dpi=300)
plt.show()
plt.close(fig)
print("✅ Saved: Fig8_region_small_multiples.png")

out9 = None
if PERM_CSV and os.path.exists(PERM_CSV):
    dfp = pd.read_csv(PERM_CSV)
    region_col = next((c for c in dfp.columns if "region" in c.lower() or "区域" in c), None)
    feat_col   = next((c for c in dfp.columns if "feature" in c.lower() or "特征" in c), None)
    imp_col    = next((c for c in dfp.columns if "importance" in c.lower() or "重要" in c), None)
    if region_col and feat_col and imp_col:
        gg = (dfp[[region_col, feat_col, imp_col]]
              .groupby(region_col, as_index=False)
              .apply(lambda x: x.sort_values(imp_col, ascending=False).head(5))
              .reset_index(drop=True))
        regs = gg[region_col].unique().tolist()
        ncol = min(3, len(regs)); nrow = (len(regs)+ncol-1)//ncol
        fig, axes = plt.subplots(nrow, ncol, figsize=(5*ncol, 3.5*nrow), squeeze=False)
        for i, reg in enumerate(regs):
            r,c = divmod(i, ncol)
            gi = gg[gg[region_col]==reg]
            axes[r,c].barh(gi[feat_col], gi[imp_col])
            axes[r,c].invert_yaxis()
            axes[r,c].set_title(reg); axes[r,c].set_xlabel("Permutation importance")
        for j in range(len(regs), nrow*ncol): r,c = divmod(j, ncol); axes[r,c].axis("off")
        plt.tight_layout(); out9 = "Fig9_permutation_importance.png"; plt.savefig(out9, dpi=300); plt.show(); plt.close(fig)
        print("Saved:", out9)

elif TOP3_CSV and os.path.exists(TOP3_CSV):
    dft = pd.read_csv(TOP3_CSV)
    region_col = next((c for c in dft.columns if "region" in c.lower() or "区域" in c), None)
    feat_col   = next((c for c in dft.columns if "feature" in c.lower() or "特征" in c), None)
    score_col  = next((c for c in dft.columns if "score" in c.lower() or "重要" in c), None)
    if region_col and feat_col and score_col:
        regs = dft[region_col].unique().tolist()
        ncol = min(3, len(regs)); nrow = (len(regs)+ncol-1)//ncol
        fig, axes = plt.subplots(nrow, ncol, figsize=(5*ncol, 3.5*nrow), squeeze=False)
        for i, reg in enumerate(regs):
            r,c = divmod(i, ncol)
            gi = dft[dft[region_col]==reg]
            axes[r,c].barh(gi[feat_col], gi[score_col])
            axes[r,c].invert_yaxis()
            axes[r,c].set_title(reg); axes[r,c].set_xlabel("Top-3 score")
        for j in range(len(regs), nrow*ncol): r,c = divmod(j, ncol); axes[r,c].axis("off")
        plt.tight_layout(); out9 = "Fig9_top3_features.png"; plt.savefig(out9, dpi=300); plt.show(); plt.close(fig)
        print("Saved:", out9)
else:
    print("未找到重要度/Top-3 CSV，跳过 Fig.9")

from google.colab import files
outs = ["Fig2_sample_triptych.png","Fig3_qualitative_comparison.png",
        "Fig6_global_trends.png","Fig7_region_trends.png",
        "Fig8_region_small_multiples.png",
        "Fig9_permutation_importance.png","Fig9_top3_features.png"]
outs = [f for f in outs if os.path.exists(f)]

if SAVE_TO_DRIVE and MODE=="drive":
    import shutil, os
    out_dir = os.path.join(DRIVE_ROOT, "figs_out")
    os.makedirs(out_dir, exist_ok=True)
    for f in outs:
        shutil.copy2(f, os.path.join(out_dir, f))
    print("✅ 已拷贝到：", out_dir)

print("👇 选择需要下载的图片（可多选）：")
for f in outs:
    files.download(f)