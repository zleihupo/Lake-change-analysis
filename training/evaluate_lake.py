# -*- coding: utf-8 -*-
"""evaluate lake.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16kR4Qzt8aML-jnLPTHCkLKWMuiFE6Njr
"""

from google.colab import drive
drive.mount('/content/drive')

# =============================================
# ğŸš€ Fast Evaluate + Soft Voting (cached preds, vectorized metrics)
# =============================================
import os, glob
import numpy as np
import tensorflow as tf
import cv2
from tqdm import tqdm
import pandas as pd

from sklearn.metrics import f1_score, jaccard_score, accuracy_score, precision_score, recall_score

# ---- Paths ----
UNET_PATH   = '/content/drive/My Drive/unet_model_final.h5'
SEGNET_PATH = '/content/drive/My Drive/segnet_model_final.h5'
FCN_PATH    = '/content/drive/My Drive/fcn_model_final.h5'

TEST_IMG_DIR = '/content/drive/My Drive/dataset/test/images/'
TEST_MASK_DIR= '/content/drive/My Drive/dataset/test/masks/'
VAL_IMG_DIR  = '/content/drive/My Drive/dataset/val/images/'   # optional
VAL_MASK_DIR = '/content/drive/My Drive/dataset/val/masks/'    # optional

IMG_SIZE = (256,256)
BATCH    = 64  # try 64/128 on A100

# ---- Data loader ----
def load_data(img_dir, mask_dir, img_size=(256,256)):
    files = sorted(glob.glob(os.path.join(img_dir, '*')))
    X, y = [], []
    for p in tqdm(files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        name = os.path.basename(p)
        mpath = os.path.join(mask_dir, name.replace('.jpg','.png'))
        im = cv2.imread(p); ms = cv2.imread(mpath, cv2.IMREAD_GRAYSCALE)
        if im is None or ms is None: continue
        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
        im = cv2.resize(im, img_size).astype(np.float32)/255.0
        ms = cv2.resize(ms, img_size, interpolation=cv2.INTER_NEAREST)
        ms = (ms>127).astype(np.uint8)
        X.append(im); y.append(ms)
    X = np.asarray(X, np.float32)
    y = np.asarray(y, np.uint8)
    return X, y

# ---- Cache helpers ----
def squeeze(p): return p[...,0] if (p.ndim==4 and p.shape[-1]==1) else p

def get_or_predict(model_path, X, cache_name):
    npy = cache_name + '.npy'
    if os.path.exists(npy):
        return np.load(npy)                          # (N,H,W)
    model = tf.keras.models.load_model(model_path, compile=False)
    P = squeeze(model.predict(X, batch_size=BATCH, verbose=0))
    np.save(npy, P)
    return P

# ---- Load once ----
x_test, y_test = load_data(TEST_IMG_DIR, TEST_MASK_DIR, IMG_SIZE)
y_test_flat = y_test.reshape(-1)                     # (N*H*W,)

# optional val for threshold tuning
x_val = y_val = None
if os.path.isdir(VAL_IMG_DIR) and os.path.isdir(VAL_MASK_DIR):
    x_val, y_val = load_data(VAL_IMG_DIR, VAL_MASK_DIR, IMG_SIZE)
    y_val_flat = y_val.reshape(-1)

# ---- Predict or load cached ----
p_unet = get_or_predict(UNET_PATH,  x_test, 'pred_unet_test')
p_seg  = get_or_predict(SEGNET_PATH,x_test, 'pred_segnet_test')
p_fcn  = get_or_predict(FCN_PATH,   x_test, 'pred_fcn_test')

if x_val is not None:
    p_unet_v = get_or_predict(UNET_PATH,  x_val, 'pred_unet_val')
    p_seg_v  = get_or_predict(SEGNET_PATH,x_val, 'pred_segnet_val')
    p_fcn_v  = get_or_predict(FCN_PATH,   x_val, 'pred_fcn_val')

# ---- Fast metrics (vectorized for whole dataset) ----
def metrics_from_flat(y_true_flat, y_pred_flat):
    # y_* are 0/1 uint8 flat arrays
    tp = np.logical_and(y_true_flat==1, y_pred_flat==1).sum()
    tn = np.logical_and(y_true_flat==0, y_pred_flat==0).sum()
    fp = np.logical_and(y_true_flat==0, y_pred_flat==1).sum()
    fn = np.logical_and(y_true_flat==1, y_pred_flat==0).sum()

    prec = tp / (tp+fp+1e-9)
    rec  = tp / (tp+fn+1e-9)
    acc  = (tp+tn) / (tp+tn+fp+fn+1e-9)
    iou  = tp / (tp+fp+fn+1e-9)
    f1   = 2*prec*rec / (prec+rec+1e-9)
    return f1, iou, acc, prec, rec

def best_threshold_from_probs(p_flat, y_true_flat, lo=0.3, hi=0.7, steps=41):
    best_t, best_m = 0.5, -1
    for t in np.linspace(lo, hi, steps):
        yb = (p_flat > t).astype(np.uint8)
        f1, *_ = metrics_from_flat(y_true_flat, yb)
        if f1 > best_m:
            best_m, best_t = f1, float(t)
    return best_t, best_m

# ---- Tune thresholds for single models (on val if available) ----
def tune_or_fixed(p_test, name):
    if x_val is None:
        return 0.5
    p_flat = p_test  # placeholder
    t,_ = best_threshold_from_probs(
        p_flat = p_unet_v.reshape(-1) if name=='U' else p_seg_v.reshape(-1) if name=='S' else p_fcn_v.reshape(-1),
        y_true_flat = y_val_flat
    )
    print(f"[{name}] best thr on val: {t:.3f}")
    return t

t_unet = tune_or_fixed(p_unet, 'U')
t_seg  = tune_or_fixed(p_seg,  'S')
t_fcn  = tune_or_fixed(p_fcn,  'F')

# ---- Single models (vectorized metrics) ----
y_unet = (p_unet.reshape(-1) > t_unet).astype(np.uint8)
y_seg  = (p_seg.reshape(-1)  > t_seg ).astype(np.uint8)
y_fcn  = (p_fcn.reshape(-1)  > t_fcn ).astype(np.uint8)

print("\n[Single models @ tuned threshold]")
for name, yb in [('U-Net',y_unet),('SegNet',y_seg),('FCN',y_fcn)]:
    f1,iou,acc,prec,rec = metrics_from_flat(y_test_flat, yb)
    print(f"{name:6s} â†’ F1={f1:.4f}, IoU={iou:.4f}, Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}")

# ---- Ensemble grid (use cached probs; vectorized; val-tuned thr if available) ----
weights = np.arange(0.0, 1.0001, 0.1)
rows, best = [], {'F1':-1}

# precompute val thr per weight if val exists (optional, else 0.5)
def ens_thr(wu,ws,wf):
    if x_val is None: return 0.5
    p_ens_v = wu*p_unet_v + ws*p_seg_v + wf*p_fcn_v
    t,_ = best_threshold_from_probs(p_ens_v.reshape(-1), y_val_flat)
    return t

for wu in weights:
    for ws in weights:
        if wu+ws>1.0: continue
        wf = 1.0 - wu - ws
        t = ens_thr(wu,ws,wf)

        p_ens = wu*p_unet + ws*p_seg + wf*p_fcn
        yb = (p_ens.reshape(-1) > t).astype(np.uint8)

        f1,iou,acc,prec,rec = metrics_from_flat(y_test_flat, yb)
        rows.append([wu,ws,wf,t,f1,iou,acc,prec,rec])
        if f1>best['F1']:
            best = {"wu":wu,"ws":ws,"wf":wf,"t":t,"F1":f1,"IoU":iou,"Acc":acc,"Prec":prec,"Rec":rec}

df = pd.DataFrame(rows, columns=["U-Net","SegNet","FCN","Thresh","F1","IoU","Accuracy","Precision","Recall"])
df = df.sort_values('F1', ascending=False).reset_index(drop=True)
df.to_csv("grid_search_ensemble_results.csv", index=False)

print("\nğŸ† Best (F1): (wu,ws,wf) =", (best['wu'],best['ws'],best['wf']),
      " thr=", round(best['t'],3))
print("   â†’ F1={F1:.4f}, IoU={IoU:.4f}, Acc={Acc:.4f}, Prec={Prec:.4f}, Rec={Rec:.4f}".format(**best))
print("Saved: grid_search_ensemble_results.csv")

# (å¯é€‰) æŠŠä¸‰ç»„æµ‹è¯•æ¦‚ç‡ä¹Ÿä¿å­˜ï¼Œåç»­è¯„ä¼°ç›´æ¥è¯»
np.save("pred_unet_test.npy", p_unet)
np.save("pred_segnet_test.npy", p_seg)
np.save("pred_fcn_test.npy",  p_fcn)
if x_val is not None:
    np.save("pred_unet_val.npy", p_unet_v)
    np.save("pred_segnet_val.npy", p_seg_v)
    np.save("pred_fcn_val.npy",  p_fcn_v)

# =============================================
# ğŸ“Š å¯è§†åŒ–ï¼ˆMatplotlib-only, fastï¼‰
# ç›´æ¥æ¥åœ¨ä¸Šé¢è„šæœ¬ç»“å°¾å¤„
# éœ€è¦å˜é‡ï¼šdfï¼ˆæƒé‡ç»„åˆç»“æœè¡¨ï¼‰ã€bestã€y_unet/y_seg/y_fcnã€y_test_flatã€metrics_from_flat
# =============================================
import matplotlib.pyplot as plt
import numpy as np

# ---------- 1) Top combinations çƒ­åŠ›å›¾ï¼ˆU-Net æƒé‡ä¸º xï¼ŒSegNet æƒé‡ä¸º yï¼‰ ----------
# æ„é€  11x11 ç½‘æ ¼ï¼Œè¿‡æ»¤ wu+ws<=1 çš„ä½ç½®å¡« F1ï¼Œå…¶ä»–å¡« NaN
w_vals = np.round(np.arange(0.0, 1.0001, 0.1), 1)
grid = np.full((len(w_vals), len(w_vals)), np.nan, dtype=float)  # [SegNet(y), U-Net(x)]

for _, r in df.iterrows():
    wu, ws, f1 = round(r["U-Net"],1), round(r["SegNet"],1), r["F1"]
    xi = int(round(wu*10)); yi = int(round(ws*10))
    grid[yi, xi] = max(grid[yi, xi], f1) if not np.isnan(grid[yi, xi]) else f1

plt.figure(figsize=(8,6))
im = plt.imshow(grid, origin='lower', extent=[0,1,0,1], aspect='equal')
plt.colorbar(im, label='F1 Score')
plt.title('Soft Voting Ensemble â€” F1 Heatmap')
plt.xlabel('U-Net weight'); plt.ylabel('SegNet weight')
# ç­‰é«˜çº¿è¾…åŠ©é˜…è¯»ï¼ˆå¯é€‰ï¼‰
cs = plt.contour(np.linspace(0,1,grid.shape[1]), np.linspace(0,1,grid.shape[0]),
                 np.nan_to_num(grid, nan=-1), levels=8, linewidths=0.5)
plt.clabel(cs, inline=True, fontsize=8)
plt.tight_layout()
plt.savefig('ensemble_heatmap.png', dpi=300)
plt.close()

# ---------- 2) å•æ¨¡å‹ vs æœ€ä¼˜é›†æˆ å¯¹æ¯”æ¡å½¢å›¾ ----------
# é‡æ–°å–å•æ¨¡å‹æŒ‡æ ‡ï¼ˆåŸºäºå·²ç®—å¥½çš„ y_* ä¸ y_test_flatï¼‰
u_f1,u_iou,u_acc,u_prec,u_rec = metrics_from_flat(y_test_flat, y_unet)
s_f1,s_iou,s_acc,s_prec,s_rec = metrics_from_flat(y_test_flat, y_seg)
f_f1,f_iou,f_acc,f_prec,f_rec = metrics_from_flat(y_test_flat, y_fcn)

ens_scores = [best["F1"], best["IoU"], best["Acc"], best["Prec"], best["Rec"]]
unet_scores = [u_f1,u_iou,u_acc,u_prec,u_rec]
seg_scores  = [s_f1,s_iou,s_acc,s_prec,s_rec]
fcn_scores  = [f_f1,f_iou,f_acc,f_prec,f_rec]

labels = ["F1","IoU","Accuracy","Precision","Recall"]
x = np.arange(len(labels)); w = 0.2

plt.figure(figsize=(10,6))
plt.bar(x - 1.5*w, unet_scores, width=w, label='U-Net')
plt.bar(x - 0.5*w, seg_scores,  width=w, label='SegNet')
plt.bar(x + 0.5*w, fcn_scores,  width=w, label='FCN')
plt.bar(x + 1.5*w, ens_scores,  width=w, label='Ensemble (best)')
plt.xticks(x, labels); plt.ylim(0,1.0)
plt.title('Single Models vs Best Ensemble')
plt.ylabel('Score'); plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.legend(loc='lower right')
plt.tight_layout()
plt.savefig('model_vs_ensemble.png', dpi=300)
plt.close()

print("Saved figures: ensemble_heatmap.png, model_vs_ensemble.png")

import zipfile
import os
from google.colab import files

# å‡è®¾è¦æ‰“åŒ…çš„æ–‡ä»¶
files_to_zip = [
    "grid_search_ensemble_results.csv",
    "ensemble_heatmap.png",
    "model_vs_ensemble.png",
    "pred_unet_test.npy",
    "pred_segnet_test.npy",
    "pred_fcn_test.npy"
]

files_existing = [f for f in files_to_zip if os.path.exists(f)]

zip_path = "/content/evaluation_results.zip"  # æ”¹æˆ /content
with zipfile.ZipFile(zip_path, 'w') as zf:
    for f in files_existing:
        zf.write(f, arcname=os.path.basename(f))

# ä¸‹è½½åˆ°æœ¬åœ°
files.download(zip_path)

!ls -lh /content/evaluation_results.zip