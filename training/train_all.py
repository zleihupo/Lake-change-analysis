# -*- coding: utf-8 -*-
"""train_all.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WA7Iz9zK4OdhToo9t8SBCQZr9NiJ1qNe
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
import random

# Your dataset path (after mounting Drive)
image_dir = '/content/drive/My Drive/train/img'     # all raw images
mask_dir = '/content/drive/My Drive/train/mask'     # all raw masks
output_base = '/content/drive/My Drive/dataset/'    # output path
splits = ['train', 'val', 'test']
split_ratio = {'train': 0.7, 'val': 0.1, 'test': 0.2}

# Create output directory structure
for split in splits:
    os.makedirs(os.path.join(output_base, split, 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_base, split, 'masks'), exist_ok=True)

# Collect all image filenames
all_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])
random.shuffle(all_files)
total = len(all_files)

# Split dataset
train_end = int(split_ratio['train'] * total)
val_end = train_end + int(split_ratio['val'] * total)

split_files = {
    'train': all_files[:train_end],
    'val': all_files[train_end:val_end],
    'test': all_files[val_end:]
}

# Copy files into new directories
for split, files in split_files.items():
    for f in files:
        img_src = os.path.join(image_dir, f)
        mask_name = f.replace('.jpg', '.png').replace('.jpeg', '.png')
        mask_src = os.path.join(mask_dir, mask_name)

        shutil.copy(img_src, os.path.join(output_base, split, 'images', f))
        shutil.copy(mask_src, os.path.join(output_base, split, 'masks', mask_name))

print("Dataset split completed, total:")
for k, v in split_files.items():
    print(f"{k}: {len(v)} images")

# =============================================
# ğŸ§  Step 1: Train U-Net model (train_unet.py) â€” Improved version
# Reproducible, more metrics, more stable training process
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# ---------- 1) Fix random seeds for reproducibility ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) Paths ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) Load data ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    return np.asarray(images, dtype=np.float32), np.asarray(masks, dtype=np.float32)

x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)

print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) Metrics (IoU / Dice) ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection
    return (intersection + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)
    intersection = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * intersection + smooth) / (denom + smooth)

# ---------- 5) U-Net model ----------
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    def conv_block(x, filters, drop=False):
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        if drop:
            x = Dropout(0.5)(x)
        return x

    c1 = conv_block(inputs, 64)
    p1 = MaxPooling2D()(c1)
    c2 = conv_block(p1, 128)
    p2 = MaxPooling2D()(c2)
    c3 = conv_block(p2, 256)
    p3 = MaxPooling2D()(c3)
    c4 = conv_block(p3, 512, drop=True)
    p4 = MaxPooling2D()(c4)
    c5 = conv_block(p4, 1024, drop=True)

    u6 = Conv2DTranspose(512, 2, strides=2, padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = conv_block(u6, 512)

    u7 = Conv2DTranspose(256, 2, strides=2, padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = conv_block(u7, 256)

    u8 = Conv2DTranspose(128, 2, strides=2, padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = conv_block(u8, 128)

    u9 = Conv2DTranspose(64, 2, strides=2, padding='same')(c8)
    u9 = concatenate([u9, c1])
    c9 = conv_block(u9, 64)

    outputs = Conv2D(1, 1, activation='sigmoid')(c9)
    return Model(inputs, outputs)

model = unet_model(input_size=(IMG_SIZE[0], IMG_SIZE[1], 3))
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',          # same as original; can switch to BCE+Dice if needed
    metrics=['accuracy', iou_metric, dice_coef]
)

# ---------- 6) Training callbacks ----------
ckpt_path = '/content/drive/My Drive/unet_model_best.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1)
]

# ---------- 7) Train ----------
history = model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=100,                 # aligned with paper training strength
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 8) Save final model ----------
final_path = '/content/drive/My Drive/unet_model_final.h5'
model.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")

# =============================================
# ğŸ§  Step 2: Train SegNet model (train_segnet.py) â€” Improved version
# Reproducible, more metrics, more stable training
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tqdm import tqdm
from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, UpSampling2D,
                                     Conv2DTranspose, BatchNormalization,
                                     Activation, Dropout)
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# ---------- 1) Fix random seeds ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) Data paths ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) Load data ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue
        # Use nearest neighbor for mask to keep edges clean
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    return np.asarray(images, dtype=np.float32), np.asarray(masks, dtype=np.float32)

x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)
print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) Metrics (IoU / Dice) ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter
    return (inter + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * inter + smooth) / (denom + smooth)

# ---------- 5) SegNet model ----------
def build_segnet(input_shape=(256, 256, 3)):
    inputs = Input(shape=input_shape)

    # Encoder
    x = Conv2D(64,  (3,3), padding='same')(inputs); x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(128, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(256, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    # Bottleneck (optional Dropout for regularization)
    x = Conv2D(512, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = Dropout(0.3)(x)

    # Decoder (UpSampling approximates SegNet upsampling)
    x = UpSampling2D()(x)
    x = Conv2DTranspose(256, (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(128, (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(64,  (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    outputs = Conv2DTranspose(1, (1,1), activation='sigmoid')(x)
    return Model(inputs, outputs)

segnet = build_segnet(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
segnet.compile(optimizer='adam',
               loss='binary_crossentropy',
               metrics=['accuracy', iou_metric, dice_coef])

# ---------- 6) Training callbacks ----------
ckpt_path  = '/content/drive/My Drive/segnet_model_best.h5'
final_path = '/content/drive/My Drive/segnet_model_final.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1),
]

# ---------- 7) Train ----------
history = segnet.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=100,
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 8) Save ----------
segnet.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")

# =============================================
# ğŸ§  Step 3: Train FCN model (train_fcn.py) â€” Improved version
# Reproducible, more metrics, more stable training; FCN-8s style skip connections and upsampling
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Add, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# ---------- 1) Fix random seeds ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) Data paths ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) Load data ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    # List common image extensions, not only .jpg
    patterns = ["*.jpg", "*.jpeg", "*.png", "*.tif", "*.tiff", "*.bmp"]
    img_files = []
    for pat in patterns:
        img_files.extend(glob.glob(os.path.join(img_dir, pat)))
    img_files = sorted(img_files)

    if len(img_files) == 0:
        raise FileNotFoundError(f"No images found in: {img_dir}")

    images, masks = [], []

    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)

        # Allow original images to be .png/.tif etc., masks must have the same stem + .png/.jpg
        stem, _ = os.path.splitext(fname)
        mpath_candidates = [
            os.path.join(mask_dir, stem + ".png"),
            os.path.join(mask_dir, stem + ".jpg"),
            os.path.join(mask_dir, stem + ".tif"),
        ]
        mask_path = next((p for p in mpath_candidates if os.path.exists(p)), None)
        if mask_path is None:
            raise FileNotFoundError(f"Mask not found for image: {fname} in {mask_dir}")

        img = cv2.imread(img_path)
        if img is None:
            raise ValueError(f"Failed to read image: {img_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            raise ValueError(f"Failed to read mask: {mask_path}")
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    X = np.asarray(images, dtype=np.float32)
    y = np.asarray(masks, dtype=np.float32)

    if X.size == 0 or y.size == 0:
        raise RuntimeError("Loaded empty arrays â€” check img/mask directories and names.")

    return X, y

x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)
print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) Metrics (IoU / Dice) ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter
    return (inter + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * inter + smooth) / (denom + smooth)

# ---------- 5) FCN model (VGG16 backbone, FCN-8s skip connections) ----------
def build_fcn(input_shape=(256, 256, 3)):
    vgg = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)

    # Feature maps
    f3 = vgg.get_layer('block3_pool').output   # 1/8
    f4 = vgg.get_layer('block4_pool').output   # 1/16
    f5 = vgg.get_layer('block5_pool').output   # 1/32

    # Classifier replacement (logits)
    o = Conv2D(512, (7, 7), padding='same', activation='relu')(f5)
    o = Conv2D(512, (1, 1), padding='same', activation='relu')(o)
    o = Conv2D(1,   (1, 1), padding='same', activation=None)(o)

    # 1/32 -> 1/16
    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=None)(o)
    o2 = Conv2D(1, (1, 1), padding='same', activation=None)(f4)
    o = Add()([o, o2])

    # 1/16 -> 1/8
    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=None)(o)
    o3 = Conv2D(1, (1, 1), padding='same', activation=None)(f3)
    o = Add()([o, o3])

    # 1/8 -> 1/1
    o = Conv2DTranspose(1, kernel_size=(8, 8), strides=(8, 8), padding='same', activation=None)(o)

    # Sigmoid
    o = Activation('sigmoid')(o)

    model = Model(inputs=vgg.input, outputs=o)
    return model

fcn = build_fcn(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))

# Freeze backbone for warmup
for layer in fcn.layers:
    if layer.name.startswith('block'):
        layer.trainable = False

fcn.compile(optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy', iou_metric, dice_coef])

ckpt_path  = '/content/drive/My Drive/fcn_model_best.h5'
final_path = '/content/drive/My Drive/fcn_model_final.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1),
]

# ---------- 6) Train: warmup + optional fine-tune ----------
history1 = fcn.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=20,
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# Fine-tune: unfreeze block5
for layer in fcn.layers:
    if layer.name.startswith('block5'):
        layer.trainable = True
fcn.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
            loss='binary_crossentropy',
            metrics=['accuracy', iou_metric, dice_coef])

history2 = fcn.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=80,
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 7) Save ----------
fcn.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")
