# -*- coding: utf-8 -*-
"""train_all.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WA7Iz9zK4OdhToo9t8SBCQZr9NiJ1qNe
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
import random

# 你的数据路径（上传后挂载路径）
image_dir = '/content/drive/My Drive/train/img'   # 所有原始图像
mask_dir = '/content/drive/My Drive/train/mask'     # 所有原始掩膜
output_base = '/content/drive/My Drive/dataset/'    # 输出路径
splits = ['train', 'val', 'test']
split_ratio = {'train': 0.7, 'val': 0.1, 'test': 0.2}

# 创建输出结构
for split in splits:
    os.makedirs(os.path.join(output_base, split, 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_base, split, 'masks'), exist_ok=True)

# 收集所有图像文件名
all_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])
random.shuffle(all_files)
total = len(all_files)

# 划分
train_end = int(split_ratio['train'] * total)
val_end = train_end + int(split_ratio['val'] * total)

split_files = {
    'train': all_files[:train_end],
    'val': all_files[train_end:val_end],
    'test': all_files[val_end:]
}

# 复制文件到新目录
for split, files in split_files.items():
    for f in files:
        img_src = os.path.join(image_dir, f)
        mask_name = f.replace('.jpg', '.png').replace('.jpeg', '.png')
        mask_src = os.path.join(mask_dir, mask_name)

        shutil.copy(img_src, os.path.join(output_base, split, 'images', f))
        shutil.copy(mask_src, os.path.join(output_base, split, 'masks', mask_name))

print("数据划分完成，共计：")
for k, v in split_files.items():
    print(f"{k}: {len(v)} 张图")

# =============================================
# 🧠 第二步：训练 U-Net 模型（train_unet.py）— 改进版
# 可复现、指标更全、训练流程更稳
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# ---------- 1) 固定随机种子：结果更可复现 ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) 路径 ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) 数据读取 ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    return np.asarray(images, dtype=np.float32), np.asarray(masks, dtype=np.float32)

x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)

print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) 评价指标（IoU / Dice） ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection
    return (intersection + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)
    intersection = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * intersection + smooth) / (denom + smooth)

# ---------- 5) U-Net 模型 ----------
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    def conv_block(x, filters, drop=False):
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        if drop:
            x = Dropout(0.5)(x)
        return x

    c1 = conv_block(inputs, 64)
    p1 = MaxPooling2D()(c1)
    c2 = conv_block(p1, 128)
    p2 = MaxPooling2D()(c2)
    c3 = conv_block(p2, 256)
    p3 = MaxPooling2D()(c3)
    c4 = conv_block(p3, 512, drop=True)
    p4 = MaxPooling2D()(c4)
    c5 = conv_block(p4, 1024, drop=True)

    u6 = Conv2DTranspose(512, 2, strides=2, padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = conv_block(u6, 512)

    u7 = Conv2DTranspose(256, 2, strides=2, padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = conv_block(u7, 256)

    u8 = Conv2DTranspose(128, 2, strides=2, padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = conv_block(u8, 128)

    u9 = Conv2DTranspose(64, 2, strides=2, padding='same')(c8)
    u9 = concatenate([u9, c1])
    c9 = conv_block(u9, 64)

    outputs = Conv2D(1, 1, activation='sigmoid')(c9)
    return Model(inputs, outputs)

model = unet_model(input_size=(IMG_SIZE[0], IMG_SIZE[1], 3))
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',          # 与原实现一致；若需可换 BCE+Dice
    metrics=['accuracy', iou_metric, dice_coef]
)

# ---------- 6) 训练回调 ----------
ckpt_path = '/content/drive/My Drive/unet_model_best.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1)
]

# ---------- 7) 训练 ----------
history = model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=100,                 # 对齐论文训练强度
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 8) 保存最终模型 ----------
final_path = '/content/drive/My Drive/unet_model_final.h5'
model.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")

# =============================================
# 🧠 第三步：训练 SegNet 模型（train_segnet.py）— 改进版
# 可复现、指标更全、训练流程更稳
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tqdm import tqdm
from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, UpSampling2D,
                                     Conv2DTranspose, BatchNormalization,
                                     Activation, Dropout)
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# ---------- 1) 固定随机种子 ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) 数据路径 ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) 数据读取 ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue
        # 掩膜用最近邻插值，保持边界干净
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    return np.asarray(images, dtype=np.float32), np.asarray(masks, dtype=np.float32)

x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)
print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) 指标（IoU / Dice） ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter
    return (inter + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * inter + smooth) / (denom + smooth)

# ---------- 5) SegNet 模型 ----------
def build_segnet(input_shape=(256, 256, 3)):
    inputs = Input(shape=input_shape)

    # Encoder
    x = Conv2D(64,  (3,3), padding='same')(inputs); x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(128, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(256, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    # Bottleneck（可选 Dropout 稍微正则化）
    x = Conv2D(512, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = Dropout(0.3)(x)

    # Decoder（UpSampling 近似 SegNet 的上采样）
    x = UpSampling2D()(x)
    x = Conv2DTranspose(256, (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(128, (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(64,  (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    outputs = Conv2DTranspose(1, (1,1), activation='sigmoid')(x)
    return Model(inputs, outputs)

segnet = build_segnet(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
segnet.compile(optimizer='adam',
               loss='binary_crossentropy',
               metrics=['accuracy', iou_metric, dice_coef])

# ---------- 6) 训练回调 ----------
ckpt_path  = '/content/drive/My Drive/segnet_model_best.h5'
final_path = '/content/drive/My Drive/segnet_model_final.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1),
]

# ---------- 7) 训练 ----------
history = segnet.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=100,
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 8) 保存 ----------
segnet.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")

# =============================================
# 🧠 第四步：训练 FCN 模型（train_fcn.py）— 改进版
# 可复现、指标更全、训练流程更稳；FCN-8s 风格的跳连与上采样
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Add, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# ---------- 1) 固定随机种子 ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) 数据路径 ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) 数据读取 ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    # 列出常见图片后缀，避免只匹配到 .jpg
    patterns = ["*.jpg", "*.jpeg", "*.png", "*.tif", "*.tiff", "*.bmp"]
    img_files = []
    for pat in patterns:
        img_files.extend(glob.glob(os.path.join(img_dir, pat)))
    img_files = sorted(img_files)

    if len(img_files) == 0:
        raise FileNotFoundError(f"No images found in: {img_dir}")

    images, masks = [], []

    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)

        # 允许原图是 .png/.tif 等，掩膜统一用相同主文件名 + .png 寻找
        stem, _ = os.path.splitext(fname)
        mpath_candidates = [
            os.path.join(mask_dir, stem + ".png"),
            os.path.join(mask_dir, stem + ".jpg"),
            os.path.join(mask_dir, stem + ".tif"),
        ]
        mask_path = next((p for p in mpath_candidates if os.path.exists(p)), None)
        if mask_path is None:
            raise FileNotFoundError(f"Mask not found for image: {fname} in {mask_dir}")

        img = cv2.imread(img_path)
        if img is None:
            raise ValueError(f"Failed to read image: {img_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            raise ValueError(f"Failed to read mask: {mask_path}")
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    X = np.asarray(images, dtype=np.float32)
    y = np.asarray(masks, dtype=np.float32)

    if X.size == 0 or y.size == 0:
        raise RuntimeError("Loaded empty arrays — check img/mask directories and names.")

    return X, y
x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)
print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) 指标（IoU / Dice） ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter
    return (inter + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * inter + smooth) / (denom + smooth)

# ---------- 5) FCN 模型（VGG16 backbone, FCN-8s 跳连） ----------
def build_fcn(input_shape=(256, 256, 3)):
    vgg = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)

    # 取出三个阶段的特征
    f3 = vgg.get_layer('block3_pool').output   # 1/8
    f4 = vgg.get_layer('block4_pool').output   # 1/16
    f5 = vgg.get_layer('block5_pool').output   # 1/32

    # 顶部分类器替代（保持线性，最后再做 sigmoid）
    o = Conv2D(512, (7, 7), padding='same', activation='relu')(f5)
    o = Conv2D(512, (1, 1), padding='same', activation='relu')(o)
    o = Conv2D(1,   (1, 1), padding='same', activation=None)(o)  # logits

    # 1/32 -> 1/16，上采样并与 f4 的 1x1 logits 相加
    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=None)(o)
    o2 = Conv2D(1, (1, 1), padding='same', activation=None)(f4)
    o = Add()([o, o2])

    # 1/16 -> 1/8，上采样并与 f3 的 1x1 logits 相加
    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=None)(o)
    o3 = Conv2D(1, (1, 1), padding='same', activation=None)(f3)
    o = Add()([o, o3])

    # 1/8 -> 1/1，恢复到原尺寸
    o = Conv2DTranspose(1, kernel_size=(8, 8), strides=(8, 8), padding='same', activation=None)(o)

    # 最终 sigmoid
    o = Activation('sigmoid')(o)

    model = Model(inputs=vgg.input, outputs=o)
    return model

fcn = build_fcn(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))

# 先冻结 backbone 进行 warmup，再解冻高层微调（更稳）
for layer in fcn.layers:
    if layer.name.startswith('block'):
        layer.trainable = False

fcn.compile(optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy', iou_metric, dice_coef])

ckpt_path  = '/content/drive/My Drive/fcn_model_best.h5'
final_path = '/content/drive/My Drive/fcn_model_final.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1),
]

# ---------- 6) 训练：warmup + 可选解冻微调 ----------
# Warmup（冻结 VGG）
history1 = fcn.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=20,
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# 可选：解冻 block5 继续微调（若资源有限可跳过，或减少 epochs）
for layer in fcn.layers:
    if layer.name.startswith('block5'):
        layer.trainable = True
fcn.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
            loss='binary_crossentropy',
            metrics=['accuracy', iou_metric, dice_coef])

history2 = fcn.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=80,   # 总训练强度 ≈ 100
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 7) 保存 ----------
fcn.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")