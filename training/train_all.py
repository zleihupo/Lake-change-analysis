# -*- coding: utf-8 -*-
"""train_all.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WA7Iz9zK4OdhToo9t8SBCQZr9NiJ1qNe
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import shutil
import random

# ä½ çš„æ•°æ®è·¯å¾„ï¼ˆä¸Šä¼ åæŒ‚è½½è·¯å¾„ï¼‰
image_dir = '/content/drive/My Drive/train/img'   # æ‰€æœ‰åŸå§‹å›¾åƒ
mask_dir = '/content/drive/My Drive/train/mask'     # æ‰€æœ‰åŸå§‹æ©è†œ
output_base = '/content/drive/My Drive/dataset/'    # è¾“å‡ºè·¯å¾„
splits = ['train', 'val', 'test']
split_ratio = {'train': 0.7, 'val': 0.1, 'test': 0.2}

# åˆ›å»ºè¾“å‡ºç»“æ„
for split in splits:
    os.makedirs(os.path.join(output_base, split, 'images'), exist_ok=True)
    os.makedirs(os.path.join(output_base, split, 'masks'), exist_ok=True)

# æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶å
all_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])
random.shuffle(all_files)
total = len(all_files)

# åˆ’åˆ†
train_end = int(split_ratio['train'] * total)
val_end = train_end + int(split_ratio['val'] * total)

split_files = {
    'train': all_files[:train_end],
    'val': all_files[train_end:val_end],
    'test': all_files[val_end:]
}

# å¤åˆ¶æ–‡ä»¶åˆ°æ–°ç›®å½•
for split, files in split_files.items():
    for f in files:
        img_src = os.path.join(image_dir, f)
        mask_name = f.replace('.jpg', '.png').replace('.jpeg', '.png')
        mask_src = os.path.join(mask_dir, mask_name)

        shutil.copy(img_src, os.path.join(output_base, split, 'images', f))
        shutil.copy(mask_src, os.path.join(output_base, split, 'masks', mask_name))

print("æ•°æ®åˆ’åˆ†å®Œæˆï¼Œå…±è®¡ï¼š")
for k, v in split_files.items():
    print(f"{k}: {len(v)} å¼ å›¾")

# =============================================
# ğŸ§  ç¬¬äºŒæ­¥ï¼šè®­ç»ƒ U-Net æ¨¡å‹ï¼ˆtrain_unet.pyï¼‰â€” æ”¹è¿›ç‰ˆ
# å¯å¤ç°ã€æŒ‡æ ‡æ›´å…¨ã€è®­ç»ƒæµç¨‹æ›´ç¨³
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# ---------- 1) å›ºå®šéšæœºç§å­ï¼šç»“æœæ›´å¯å¤ç° ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) è·¯å¾„ ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) æ•°æ®è¯»å– ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    return np.asarray(images, dtype=np.float32), np.asarray(masks, dtype=np.float32)

x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)

print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) è¯„ä»·æŒ‡æ ‡ï¼ˆIoU / Diceï¼‰ ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)
    intersection = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection
    return (intersection + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.cast(y_pred, tf.float32)
    y_pred = tf.clip_by_value(y_pred, 0.0, 1.0)
    intersection = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * intersection + smooth) / (denom + smooth)

# ---------- 5) U-Net æ¨¡å‹ ----------
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    def conv_block(x, filters, drop=False):
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        x = Conv2D(filters, 3, activation='relu', padding='same')(x)
        if drop:
            x = Dropout(0.5)(x)
        return x

    c1 = conv_block(inputs, 64)
    p1 = MaxPooling2D()(c1)
    c2 = conv_block(p1, 128)
    p2 = MaxPooling2D()(c2)
    c3 = conv_block(p2, 256)
    p3 = MaxPooling2D()(c3)
    c4 = conv_block(p3, 512, drop=True)
    p4 = MaxPooling2D()(c4)
    c5 = conv_block(p4, 1024, drop=True)

    u6 = Conv2DTranspose(512, 2, strides=2, padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = conv_block(u6, 512)

    u7 = Conv2DTranspose(256, 2, strides=2, padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = conv_block(u7, 256)

    u8 = Conv2DTranspose(128, 2, strides=2, padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = conv_block(u8, 128)

    u9 = Conv2DTranspose(64, 2, strides=2, padding='same')(c8)
    u9 = concatenate([u9, c1])
    c9 = conv_block(u9, 64)

    outputs = Conv2D(1, 1, activation='sigmoid')(c9)
    return Model(inputs, outputs)

model = unet_model(input_size=(IMG_SIZE[0], IMG_SIZE[1], 3))
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',          # ä¸åŸå®ç°ä¸€è‡´ï¼›è‹¥éœ€å¯æ¢ BCE+Dice
    metrics=['accuracy', iou_metric, dice_coef]
)

# ---------- 6) è®­ç»ƒå›è°ƒ ----------
ckpt_path = '/content/drive/My Drive/unet_model_best.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1)
]

# ---------- 7) è®­ç»ƒ ----------
history = model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=100,                 # å¯¹é½è®ºæ–‡è®­ç»ƒå¼ºåº¦
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 8) ä¿å­˜æœ€ç»ˆæ¨¡å‹ ----------
final_path = '/content/drive/My Drive/unet_model_final.h5'
model.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")

# =============================================
# ğŸ§  ç¬¬ä¸‰æ­¥ï¼šè®­ç»ƒ SegNet æ¨¡å‹ï¼ˆtrain_segnet.pyï¼‰â€” æ”¹è¿›ç‰ˆ
# å¯å¤ç°ã€æŒ‡æ ‡æ›´å…¨ã€è®­ç»ƒæµç¨‹æ›´ç¨³
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tqdm import tqdm
from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, UpSampling2D,
                                     Conv2DTranspose, BatchNormalization,
                                     Activation, Dropout)
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# ---------- 1) å›ºå®šéšæœºç§å­ ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) æ•°æ®è·¯å¾„ ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) æ•°æ®è¯»å– ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    images, masks = [], []
    img_files = sorted(glob.glob(os.path.join(img_dir, '*')))
    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)
        mask_path = os.path.join(mask_dir, fname.replace('.jpg', '.png'))

        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            continue
        # æ©è†œç”¨æœ€è¿‘é‚»æ’å€¼ï¼Œä¿æŒè¾¹ç•Œå¹²å‡€
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    return np.asarray(images, dtype=np.float32), np.asarray(masks, dtype=np.float32)

x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)
print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) æŒ‡æ ‡ï¼ˆIoU / Diceï¼‰ ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter
    return (inter + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * inter + smooth) / (denom + smooth)

# ---------- 5) SegNet æ¨¡å‹ ----------
def build_segnet(input_shape=(256, 256, 3)):
    inputs = Input(shape=input_shape)

    # Encoder
    x = Conv2D(64,  (3,3), padding='same')(inputs); x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(128, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    x = Conv2D(256, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = MaxPooling2D()(x)

    # Bottleneckï¼ˆå¯é€‰ Dropout ç¨å¾®æ­£åˆ™åŒ–ï¼‰
    x = Conv2D(512, (3,3), padding='same')(x);     x = BatchNormalization()(x); x = Activation('relu')(x)
    x = Dropout(0.3)(x)

    # Decoderï¼ˆUpSampling è¿‘ä¼¼ SegNet çš„ä¸Šé‡‡æ ·ï¼‰
    x = UpSampling2D()(x)
    x = Conv2DTranspose(256, (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(128, (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    x = UpSampling2D()(x)
    x = Conv2DTranspose(64,  (3,3), padding='same')(x); x = BatchNormalization()(x); x = Activation('relu')(x)

    outputs = Conv2DTranspose(1, (1,1), activation='sigmoid')(x)
    return Model(inputs, outputs)

segnet = build_segnet(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
segnet.compile(optimizer='adam',
               loss='binary_crossentropy',
               metrics=['accuracy', iou_metric, dice_coef])

# ---------- 6) è®­ç»ƒå›è°ƒ ----------
ckpt_path  = '/content/drive/My Drive/segnet_model_best.h5'
final_path = '/content/drive/My Drive/segnet_model_final.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1),
]

# ---------- 7) è®­ç»ƒ ----------
history = segnet.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=100,
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 8) ä¿å­˜ ----------
segnet.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")

# =============================================
# ğŸ§  ç¬¬å››æ­¥ï¼šè®­ç»ƒ FCN æ¨¡å‹ï¼ˆtrain_fcn.pyï¼‰â€” æ”¹è¿›ç‰ˆ
# å¯å¤ç°ã€æŒ‡æ ‡æ›´å…¨ã€è®­ç»ƒæµç¨‹æ›´ç¨³ï¼›FCN-8s é£æ ¼çš„è·³è¿ä¸ä¸Šé‡‡æ ·
# =============================================
import os, random, glob
import numpy as np
import tensorflow as tf
import cv2
from tqdm import tqdm
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Add, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# ---------- 1) å›ºå®šéšæœºç§å­ ----------
SEED = 7
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

# ---------- 2) æ•°æ®è·¯å¾„ ----------
train_img_path = '/content/drive/My Drive/dataset/train/images/'
train_mask_path = '/content/drive/My Drive/dataset/train/masks/'
val_img_path   = '/content/drive/My Drive/dataset/val/images/'
val_mask_path  = '/content/drive/My Drive/dataset/val/masks/'

IMG_SIZE = (256, 256)

# ---------- 3) æ•°æ®è¯»å– ----------
def load_data(img_dir, mask_dir, img_size=(256, 256)):
    # åˆ—å‡ºå¸¸è§å›¾ç‰‡åç¼€ï¼Œé¿å…åªåŒ¹é…åˆ° .jpg
    patterns = ["*.jpg", "*.jpeg", "*.png", "*.tif", "*.tiff", "*.bmp"]
    img_files = []
    for pat in patterns:
        img_files.extend(glob.glob(os.path.join(img_dir, pat)))
    img_files = sorted(img_files)

    if len(img_files) == 0:
        raise FileNotFoundError(f"No images found in: {img_dir}")

    images, masks = [], []

    for img_path in tqdm(img_files, desc=f'Loading {os.path.basename(os.path.normpath(img_dir))}'):
        fname = os.path.basename(img_path)

        # å…è®¸åŸå›¾æ˜¯ .png/.tif ç­‰ï¼Œæ©è†œç»Ÿä¸€ç”¨ç›¸åŒä¸»æ–‡ä»¶å + .png å¯»æ‰¾
        stem, _ = os.path.splitext(fname)
        mpath_candidates = [
            os.path.join(mask_dir, stem + ".png"),
            os.path.join(mask_dir, stem + ".jpg"),
            os.path.join(mask_dir, stem + ".tif"),
        ]
        mask_path = next((p for p in mpath_candidates if os.path.exists(p)), None)
        if mask_path is None:
            raise FileNotFoundError(f"Mask not found for image: {fname} in {mask_dir}")

        img = cv2.imread(img_path)
        if img is None:
            raise ValueError(f"Failed to read image: {img_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)
        img = (img / 255.0).astype(np.float32)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            raise ValueError(f"Failed to read mask: {mask_path}")
        mask = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)
        mask = (mask > 127).astype(np.float32)[..., None]  # (H,W,1)

        images.append(img)
        masks.append(mask)

    X = np.asarray(images, dtype=np.float32)
    y = np.asarray(masks, dtype=np.float32)

    if X.size == 0 or y.size == 0:
        raise RuntimeError("Loaded empty arrays â€” check img/mask directories and names.")

    return X, y
x_train, y_train = load_data(train_img_path, train_mask_path, IMG_SIZE)
x_val,   y_val   = load_data(val_img_path,   val_mask_path,   IMG_SIZE)
print('Train:', x_train.shape, y_train.shape, ' Val:', x_val.shape, y_val.shape)

# ---------- 4) æŒ‡æ ‡ï¼ˆIoU / Diceï¼‰ ----------
def iou_metric(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter
    return (inter + smooth) / (union + smooth)

def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true = tf.cast(y_true, tf.float32)
    y_pred = tf.clip_by_value(tf.cast(y_pred, tf.float32), 0.0, 1.0)
    inter = tf.reduce_sum(y_true * y_pred)
    denom = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)
    return (2.0 * inter + smooth) / (denom + smooth)

# ---------- 5) FCN æ¨¡å‹ï¼ˆVGG16 backbone, FCN-8s è·³è¿ï¼‰ ----------
def build_fcn(input_shape=(256, 256, 3)):
    vgg = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)

    # å–å‡ºä¸‰ä¸ªé˜¶æ®µçš„ç‰¹å¾
    f3 = vgg.get_layer('block3_pool').output   # 1/8
    f4 = vgg.get_layer('block4_pool').output   # 1/16
    f5 = vgg.get_layer('block5_pool').output   # 1/32

    # é¡¶éƒ¨åˆ†ç±»å™¨æ›¿ä»£ï¼ˆä¿æŒçº¿æ€§ï¼Œæœ€åå†åš sigmoidï¼‰
    o = Conv2D(512, (7, 7), padding='same', activation='relu')(f5)
    o = Conv2D(512, (1, 1), padding='same', activation='relu')(o)
    o = Conv2D(1,   (1, 1), padding='same', activation=None)(o)  # logits

    # 1/32 -> 1/16ï¼Œä¸Šé‡‡æ ·å¹¶ä¸ f4 çš„ 1x1 logits ç›¸åŠ 
    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=None)(o)
    o2 = Conv2D(1, (1, 1), padding='same', activation=None)(f4)
    o = Add()([o, o2])

    # 1/16 -> 1/8ï¼Œä¸Šé‡‡æ ·å¹¶ä¸ f3 çš„ 1x1 logits ç›¸åŠ 
    o = Conv2DTranspose(1, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=None)(o)
    o3 = Conv2D(1, (1, 1), padding='same', activation=None)(f3)
    o = Add()([o, o3])

    # 1/8 -> 1/1ï¼Œæ¢å¤åˆ°åŸå°ºå¯¸
    o = Conv2DTranspose(1, kernel_size=(8, 8), strides=(8, 8), padding='same', activation=None)(o)

    # æœ€ç»ˆ sigmoid
    o = Activation('sigmoid')(o)

    model = Model(inputs=vgg.input, outputs=o)
    return model

fcn = build_fcn(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))

# å…ˆå†»ç»“ backbone è¿›è¡Œ warmupï¼Œå†è§£å†»é«˜å±‚å¾®è°ƒï¼ˆæ›´ç¨³ï¼‰
for layer in fcn.layers:
    if layer.name.startswith('block'):
        layer.trainable = False

fcn.compile(optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy', iou_metric, dice_coef])

ckpt_path  = '/content/drive/My Drive/fcn_model_best.h5'
final_path = '/content/drive/My Drive/fcn_model_final.h5'
callbacks = [
    ModelCheckpoint(ckpt_path, monitor='val_iou_metric', mode='max',
                    save_best_only=True, save_weights_only=False, verbose=1),
    ReduceLROnPlateau(monitor='val_iou_metric', mode='max',
                      factor=0.5, patience=5, min_lr=1e-6, verbose=1),
    EarlyStopping(monitor='val_iou_metric', mode='max',
                  patience=15, restore_best_weights=True, verbose=1),
]

# ---------- 6) è®­ç»ƒï¼šwarmup + å¯é€‰è§£å†»å¾®è°ƒ ----------
# Warmupï¼ˆå†»ç»“ VGGï¼‰
history1 = fcn.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=20,
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# å¯é€‰ï¼šè§£å†» block5 ç»§ç»­å¾®è°ƒï¼ˆè‹¥èµ„æºæœ‰é™å¯è·³è¿‡ï¼Œæˆ–å‡å°‘ epochsï¼‰
for layer in fcn.layers:
    if layer.name.startswith('block5'):
        layer.trainable = True
fcn.compile(optimizer=tf.keras.optimizers.Adam(1e-4),
            loss='binary_crossentropy',
            metrics=['accuracy', iou_metric, dice_coef])

history2 = fcn.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    batch_size=8,
    epochs=80,   # æ€»è®­ç»ƒå¼ºåº¦ â‰ˆ 100
    callbacks=callbacks,
    shuffle=True,
    verbose=1
)

# ---------- 7) ä¿å­˜ ----------
fcn.save(final_path)
print(f"Best checkpoint: {ckpt_path}\nFinal model: {final_path}")